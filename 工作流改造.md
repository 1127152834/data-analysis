# 工具调用模式工作流开发详细规范与实施计划

## 系统架构概述

我们将构建一个基于工具调用模式的智能工作流系统，该系统由四个主要部分组成：

1. **工具框架**：定义和管理各种工具的标准接口和注册机制
2. **智能体系统**：实现各种专门化的智能体，处理工作流的不同阶段
3. **工作流引擎**：协调智能体和工具的执行，管理状态和事件流
4. **事件系统**：处理和转换各种事件，确保与前端兼容

系统将按照以下流程处理用户请求：
`用户提问 → 优化问题 → 知识检索与问答 → 内容整理 → 结构化输出`

## 1. 工具框架详细规范

### 1.1 基础工具接口 (backend/app/autoflow/tools/base.py)

```python
from typing import Any, Dict, List, Optional, Union, TypeVar, Generic, Type
from pydantic import BaseModel, Field
import logging
import asyncio
import time
import uuid
from enum import Enum

# 工具调用状态枚举
class ToolCallStatus(str, Enum):
    STARTED = "started"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"

# 工具参数基类
class ToolParameters(BaseModel):
    """所有工具参数必须继承此类"""
    pass

# 工具结果基类
class ToolResult(BaseModel):
    """所有工具结果必须继承此类"""
    success: bool = True
    error_message: Optional[str] = None

# 泛型类型定义
P = TypeVar('P', bound=ToolParameters)
R = TypeVar('R', bound=ToolResult)

# 基础工具类
class BaseTool(Generic[P, R]):
    """所有工具必须继承此类"""
    
    # 工具元数据
    name: str
    description: str
    parameter_type: Type[P]
    result_type: Type[R]
    
    def __init__(self, name: str, description: str, parameter_type: Type[P], result_type: Type[R]):
        self.name = name
        self.description = description
        self.parameter_type = parameter_type
        self.result_type = result_type
        self.logger = logging.getLogger(f"autoflow.tools.{self.name}")
    
    async def execute(self, parameters: P) -> R:
        """执行工具逻辑，必须由子类实现"""
        raise NotImplementedError("Tool must implement execute method")
    
    def get_metadata(self) -> Dict[str, Any]:
        """获取工具元数据"""
        return {
            "name": self.name,
            "description": self.description,
            "parameters": self.parameter_type.model_json_schema(),
            "result": self.result_type.model_json_schema()
        }
```

### 1.2 工具注册器 (backend/app/autoflow/tools/registry.py)

```python
from typing import Dict, List, Type, Optional, Any
from .base import BaseTool, ToolParameters, ToolResult
import logging

logger = logging.getLogger("autoflow.tools.registry")

class ToolRegistry:
    """工具注册器，管理所有可用工具"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ToolRegistry, cls).__new__(cls)
            cls._instance._tools = {}
        return cls._instance
    
    def register_tool(self, tool: BaseTool) -> None:
        """注册工具到注册表"""
        if tool.name in self._tools:
            logger.warning(f"Tool {tool.name} already registered, overwriting")
        self._tools[tool.name] = tool
        logger.info(f"Registered tool: {tool.name}")
    
    def get_tool(self, name: str) -> Optional[BaseTool]:
        """获取指定名称的工具"""
        return self._tools.get(name)
    
    def list_tools(self) -> List[str]:
        """列出所有注册的工具名称"""
        return list(self._tools.keys())
    
    def get_tools_metadata(self) -> List[Dict[str, Any]]:
        """获取所有工具的元数据"""
        return [tool.get_metadata() for tool in self._tools.values()]
```

### 1.3 工具调用事件 (backend/app/autoflow/events/tool_events.py)

```python
from typing import Any, Dict, Optional
from pydantic import BaseModel, Field
import uuid
import time
from enum import Enum

# 事件类型枚举
class EventType(str, Enum):
    TOOL_CALL = "9"  # 工具调用
    TOOL_RESULT = "a"  # 工具结果
    STEP_END = "e"  # 步骤结束
    INFO = "8"  # 信息
    ERROR = "3"  # 错误
    TEXT = "2"  # 文本输出

# 基础事件模型
class BaseEvent(BaseModel):
    event_type: EventType
    timestamp: float = Field(default_factory=time.time)
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))

# 工具调用事件
class ToolCallEvent(BaseEvent):
    event_type: EventType = EventType.TOOL_CALL
    tool_name: str
    tool_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    parameters: Dict[str, Any]
    step: int
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "toolCallId": self.tool_id,
            "toolName": self.tool_name,
            "args": self.parameters,
            "step": self.step
        }

# 工具结果事件
class ToolResultEvent(BaseEvent):
    event_type: EventType = EventType.TOOL_RESULT
    tool_id: str
    result: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "toolCallId": self.tool_id,
            "result": self.result
        }

# 步骤结束事件
class StepEndEvent(BaseEvent):
    event_type: EventType = EventType.STEP_END
    step: int
    finish_reason: str = "stop"
    usage: Dict[str, int] = Field(default_factory=lambda: {"promptTokens": 0, "completionTokens": 0})
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "step": self.step,
            "finishReason": self.finish_reason,
            "usage": self.usage
        }

# 信息事件
class InfoEvent(BaseEvent):
    event_type: EventType = EventType.INFO
    message: str
    
    def to_dict(self) -> Dict[str, Any]:
        return {"message": self.message}

# 错误事件
class ErrorEvent(BaseEvent):
    event_type: EventType = EventType.ERROR
    message: str
    
    def to_dict(self) -> Dict[str, Any]:
        return {"message": self.message}

# 文本输出事件
class TextEvent(BaseEvent):
    event_type: EventType = EventType.TEXT
    message: str
    
    def to_dict(self) -> Dict[str, Any]:
        return {"message": self.message}
```

### 1.4 事件转换器 (backend/app/autoflow/events/converter.py)

```python
from typing import Any, Dict
from app.rag.chat.stream_protocol import ChatEvent
from app.rag.types import ChatEventType
from .tool_events import BaseEvent, EventType, ToolCallEvent, ToolResultEvent, StepEndEvent, InfoEvent, ErrorEvent, TextEvent

class EventConverter:
    """事件转换器，将内部事件转换为前端可用的ChatEvent"""
    
    @staticmethod
    def to_chat_event(event: BaseEvent) -> ChatEvent:
        """将内部事件转换为ChatEvent"""
        if event.event_type == EventType.TOOL_CALL:
            return ChatEvent(
                event_type=ChatEventType.DATA_PART,
                payload=event.to_dict()
            )
        elif event.event_type == EventType.TOOL_RESULT:
            return ChatEvent(
                event_type=ChatEventType.DATA_PART,
                payload=event.to_dict()
            )
        elif event.event_type == EventType.STEP_END:
            return ChatEvent(
                event_type=ChatEventType.DATA_PART,
                payload=event.to_dict()
            )
        elif event.event_type == EventType.INFO:
            return ChatEvent(
                event_type=ChatEventType.MESSAGE_ANNOTATIONS_PART,
                payload={"state": "INFO", "display": event.message}
            )
        elif event.event_type == EventType.ERROR:
            return ChatEvent(
                event_type=ChatEventType.ERROR_PART,
                payload=event.message
            )
        elif event.event_type == EventType.TEXT:
            return ChatEvent(
                event_type=ChatEventType.TEXT_PART,
                payload={"message": event.message}
            )
        else:
            # 默认转换为DATA_PART
            return ChatEvent(
                event_type=ChatEventType.DATA_PART,
                payload=event.to_dict()
            )
```

## 2. 智能体系统详细规范

### 2.1 智能体基类 (backend/app/autoflow/agents/base_agent.py)

```python
from typing import Any, Dict, List, Optional, AsyncGenerator
from pydantic import BaseModel
import logging
import asyncio
from sqlmodel import Session

from ..tools.registry import ToolRegistry
from ..tools.base import BaseTool, ToolParameters, ToolResult
from ..events.tool_events import BaseEvent, ToolCallEvent, ToolResultEvent, StepEndEvent, InfoEvent, ErrorEvent, TextEvent
from ..context import Context

class BaseAgent:
    """智能体基类，所有智能体必须继承此类"""
    
    def __init__(
        self, 
        name: str,
        db_session: Optional[Session] = None, 
        engine_config: Any = None,
        step_id: int = 0
    ):
        self.name = name
        self.db_session = db_session
        self.engine_config = engine_config
        self.step_id = step_id
        self.tool_registry = ToolRegistry()
        self.logger = logging.getLogger(f"autoflow.agents.{self.name}")
    
    async def process(self, context: Context) -> AsyncGenerator[BaseEvent, None]:
        """处理请求并生成事件流，必须由子类实现"""
        raise NotImplementedError("Agent must implement process method")
    
    async def call_tool(
        self, 
        tool_name: str, 
        parameters: Dict[str, Any]
    ) -> AsyncGenerator[BaseEvent, None]:
        """调用工具并生成相关事件"""
        tool = self.tool_registry.get_tool(tool_name)
        if not tool:
            self.logger.error(f"Tool {tool_name} not found")
            yield ErrorEvent(message=f"工具 {tool_name} 未找到")
            return
        
        # 生成工具调用ID
        import uuid
        tool_id = str(uuid.uuid4())
        
        try:
            # 转换参数
            param_obj = tool.parameter_type(**parameters)
            
            # 发送工具调用事件
            yield ToolCallEvent(
                tool_name=tool_name,
                tool_id=tool_id,
                parameters=parameters,
                step=self.step_id
            )
            
            # 执行工具
            result = await tool.execute(param_obj)
            
            # 发送工具结果事件
            yield ToolResultEvent(
                tool_id=tool_id,
                result=result.model_dump()
            )
            
            # 返回结果
            return result
            
        except Exception as e:
            self.logger.error(f"Error calling tool {tool_name}: {str(e)}", exc_info=True)
            yield ErrorEvent(message=f"调用工具 {tool_name} 时出错: {str(e)}")
            return None
```

### 2.2 优化问题智能体 (backend/app/autoflow/agents/question_optimizer_agent.py)

```python
from typing import Any, Dict, List, Optional, AsyncGenerator
import logging
from sqlmodel import Session

from ..tools.base import BaseTool, ToolParameters, ToolResult
from ..events.tool_events import BaseEvent, InfoEvent, ErrorEvent, TextEvent, StepEndEvent
from ..context import Context
from .base_agent import BaseAgent
from llama_index.core.prompts.rich import RichPromptTemplate

class QuestionOptimizerAgent(BaseAgent):
    """优化问题智能体，负责分析和优化用户问题"""
    
    def __init__(
        self, 
        db_session: Optional[Session] = None, 
        engine_config: Any = None,
        step_id: int = 0
    ):
        super().__init__("question_optimizer", db_session, engine_config, step_id)
        self.llm = None
        if engine_config and hasattr(engine_config, "get_llama_llm"):
            self.llm = engine_config.get_llama_llm(db_session)
    
    async def process(self, context: Context) -> AsyncGenerator[BaseEvent, None]:
        """处理用户问题，根据配置决定是否优化"""
        # 获取用户问题
        user_question = await context.get("user_question", "")
        if not user_question:
            yield ErrorEvent(message="未找到用户问题")
            return
        
        yield InfoEvent(message=f"开始分析用户问题: {user_question[:50]}...")
        
        # 检查是否需要优化问题
        should_optimize = self.engine_config.refine_question_with_kg if hasattr(self.engine_config, "refine_question_with_kg") else False
        
        if not should_optimize:
            yield InfoEvent(message="根据配置，跳过问题优化")
            await context.set("refined_question", user_question)
            yield StepEndEvent(step=self.step_id)
            return
        
        try:
            # 使用知识图谱工具获取上下文
            kg_context = ""
            async for event in self.call_tool("knowledge_graph_tool", {"query": user_question}):
                yield event
                if hasattr(event, "result") and event.result and "context" in event.result:
                    kg_context = event.result["context"]
            
            # 如果没有获取到知识图谱上下文，直接使用原问题
            if not kg_context:
                yield InfoEvent(message="未获取到知识图谱上下文，使用原始问题")
                await context.set("refined_question", user_question)
                yield StepEndEvent(step=self.step_id)
                return
            
            # 使用LLM优化问题
            if self.llm:
                yield InfoEvent(message="使用知识图谱上下文优化问题...")
                
                # 获取提示词模板
                prompt_template = RichPromptTemplate(
                    self.engine_config.llm.condense_question_prompt
                )
                
                # 执行问题优化
                refined_question = self.llm.predict(
                    prompt_template,
                    graph_knowledges=kg_context,
                    question=user_question,
                    current_date=context.get_current_date()
                )
                
                # 保存优化后的问题
                refined_question = refined_question.strip() if refined_question else user_question
                await context.set("refined_question", refined_question)
                
                yield InfoEvent(message=f"问题优化完成: {refined_question[:50]}...")
            else:
                yield InfoEvent(message="LLM未配置，使用原始问题")
                await context.set("refined_question", user_question)
        
        except Exception as e:
            self.logger.error(f"优化问题时出错: {str(e)}", exc_info=True)
            yield ErrorEvent(message=f"优化问题时出错: {str(e)}")
            await context.set("refined_question", user_question)
        
        yield StepEndEvent(step=self.step_id)
```

### 2.3 问答智能体 (backend/app/autoflow/agents/qa_agent.py)

```python
from typing import Any, Dict, List, Optional, AsyncGenerator
import logging
from sqlmodel import Session

from ..tools.base import BaseTool, ToolParameters, ToolResult
from ..events.tool_events import BaseEvent, InfoEvent, ErrorEvent, TextEvent, StepEndEvent
from ..context import Context
from .base_agent import BaseAgent
from llama_index.core.prompts.rich import RichPromptTemplate

class QAAgent(BaseAgent):
    """问答智能体，负责选择合适的工具获取答案"""
    
    def __init__(
        self, 
        db_session: Optional[Session] = None, 
        engine_config: Any = None,
        step_id: int = 1
    ):
        super().__init__("qa_agent", db_session, engine_config, step_id)
        self.llm = None
        if engine_config and hasattr(engine_config, "get_llama_llm"):
            self.llm = engine_config.get_llama_llm(db_session)
    
    async def process(self, context: Context) -> AsyncGenerator[BaseEvent, None]:
        """处理优化后的问题，选择合适的工具获取答案"""
        # 获取优化后的问题
        refined_question = await context.get("refined_question", "")
        if not refined_question:
            yield ErrorEvent(message="未找到优化后的问题")
            return
        
        yield InfoEvent(message=f"开始处理问题: {refined_question[:50]}...")
        
        try:
            # 1. 检查是否需要澄清问题
            if self.engine_config.clarify_question:
                yield InfoEvent(message="检查是否需要澄清问题...")
                
                # 调用知识图谱工具获取上下文
                kg_context = ""
                async for event in self.call_tool("knowledge_graph_tool", {"query": refined_question}):
                    yield event
                    if hasattr(event, "result") and event.result and "context" in event.result:
                        kg_context = event.result["context"]
                
                # 检查是否需要澄清
                needs_clarification = False
                clarification_msg = ""
                
                if self.llm and hasattr(self.engine_config.llm, "clarifying_question_prompt"):
                    prompt_template = RichPromptTemplate(
                        self.engine_config.llm.clarifying_question_prompt
                    )
                    
                    clarification_response = self.llm.predict(
                        prompt_template,
                        graph_knowledges=kg_context,
                        question=refined_question,
                        current_date=context.get_current_date()
                    )
                    
                    if clarification_response and isinstance(clarification_response, str):
                        lower_response = clarification_response.lower()
                        if "yes," in lower_response or "yes:" in lower_response:
                            needs_clarification = True
                            # 提取澄清消息
                            dividers = [":", "?", "because", "as", "since"]
                            for divider in dividers:
                                if divider in clarification_response:
                                    parts = clarification_response.split(divider, 1)
                                    if len(parts) > 1:
                                        clarification_msg = parts[1].strip()
                                        break
                            
                            if not clarification_msg:
                                clarification_msg = clarification_response
                
                if needs_clarification:
                    yield InfoEvent(message=f"问题需要澄清: {clarification_msg}")
                    # 在实际应用中，可能需要等待用户进一步输入
                    # 这里我们简单地记录需要澄清，然后继续处理
                    await context.set("needs_clarification", True)
                    await context.set("clarification_message", clarification_msg)
            
            # 2. 执行知识库检索
            yield InfoEvent(message="执行知识库检索...")
            knowledge_nodes = []
            
            async for event in self.call_tool("knowledge_retrieval_tool", {"query": refined_question, "top_k": 5}):
                yield event
                if hasattr(event, "result") and event.result and "nodes" in event.result:
                    knowledge_nodes = event.result["nodes"]
            
            # 3. 如果配置了数据库查询，执行数据库查询
            database_results = ""
            if self.engine_config.database.enabled:
                yield InfoEvent(message="执行数据库查询...")
                
                async for event in self.call_tool("database_query_tool", {"query": refined_question}):
                    yield event
                    if hasattr(event, "result") and event.result and "results" in event.result:
                        database_results = event.result["results"]
            
            # 4. 生成回答
            yield InfoEvent(message="生成回答...")
            
            # 准备上下文
            context_str = "\n\n".join([node.get("text", "") for node in knowledge_nodes])
            
            # 获取提示词模板
            if database_results and hasattr(self.engine_config.llm, "hybrid_response_synthesis_prompt"):
                prompt_template = RichPromptTemplate(
                    self.engine_config.llm.hybrid_response_synthesis_prompt
                )
                answer = self.llm.predict(
                    prompt_template,
                    context_str=context_str,
                    database_results=database_results,
                    query_str=refined_question
                )
            else:
                prompt_template = RichPromptTemplate(
                    self.engine_config.llm.text_qa_prompt
                )
                answer = self.llm.predict(
                    prompt_template,
                    context_str=context_str,
                    database_results=database_results,
                    graph_knowledges="",  # 这里可以添加知识图谱信息
                    query_str=refined_question,
                    original_question=await context.get("user_question", "")
                )
            
            # 保存回答
            await context.set("answer", answer)
            yield InfoEvent(message=f"回答生成完成，长度: {len(answer)}")
            
        except Exception as e:
            self.logger.error(f"生成回答时出错: {str(e)}", exc_info=True)
            yield ErrorEvent(message=f"生成回答时出错: {str(e)}")
        
        yield StepEndEvent(step=self.step_id)
```

### 2.4 内容整理智能体 (backend/app/autoflow/agents/content_organizer_agent.py)

```python
from typing import Any, Dict, List, Optional, AsyncGenerator
import logging
from sqlmodel import Session

from ..tools.base import BaseTool, ToolParameters, ToolResult
from ..events.tool_events import BaseEvent, InfoEvent, ErrorEvent, TextEvent, StepEndEvent
from ..context import Context
from .base_agent import BaseAgent
from llama_index.core.prompts.rich import RichPromptTemplate

class ContentOrganizerAgent(BaseAgent):
    """内容整理智能体，负责将原始回答整理成结构化格式"""
    
    def __init__(
        self, 
        db_session: Optional[Session] = None, 
        engine_config: Any = None,
        step_id: int = 2
    ):
        super().__init__("content_organizer", db_session, engine_config, step_id)
        self.llm = None
        if engine_config and hasattr(engine_config, "get_llama_llm"):
            self.llm = engine_config.get_llama_llm(db_session)
    
    async def process(self, context: Context) -> AsyncGenerator[BaseEvent, None]:
        """处理原始回答，整理成结构化格式"""
        # 获取原始回答
        answer = await context.get("answer", "")
        if not answer:
            yield ErrorEvent(message="未找到原始回答")
            return
        
        yield InfoEvent(message="开始整理内容...")
        
        try:
            # 如果回答已经足够结构化，可以直接使用
            if len(answer) < 1000 and ("\n\n" not in answer or "##" not in answer):
                yield InfoEvent(message="回答简短且已结构化，跳过整理")
                await context.set("organized_content", answer)
                yield StepEndEvent(step=self.step_id)
                return
            
            # 使用LLM整理内容
            if self.llm and hasattr(self.engine_config.llm, "reasoning_analysis_prompt"):
                prompt_template = RichPromptTemplate(
                    self.engine_config.llm.reasoning_analysis_prompt
                )
                
                # 获取用户问题
                user_question = await context.get("user_question", "")
                refined_question = await context.get("refined_question", user_question)
                
                # 执行内容整理
                organized_content = self.llm.predict(
                    prompt_template,
                    context_str=answer,
                    query_str=refined_question,
                    graph_knowledges="",  # 可以添加知识图谱信息
                    current_date=context.get_current_date()
                )
                
                # 保存整理后的内容
                await context.set("organized_content", organized_content)
                yield InfoEvent(message=f"内容整理完成，长度: {len(organized_content)}")
            else:
                # 如果没有配置LLM或提示词，直接使用原始回答
                yield InfoEvent(message="LLM未配置或缺少提示词模板，使用原始回答")
                await context.set("organized_content", answer)
        
        except Exception as e:
            self.logger.error(f"整理内容时出错: {str(e)}", exc_info=True)
            yield ErrorEvent(message=f"整理内容时出错: {str(e)}")
            # 出错时使用原始回答
            await context.set("organized_content", answer)
        
        yield StepEndEvent(step=self.step_id)
```

### 2.5 结构化输出智能体 (backend/app/autoflow/agents/structured_output_agent.py)

```python
from typing import Any, Dict, List, Optional, AsyncGenerator
import logging
from sqlmodel import Session

from ..tools.base import BaseTool, ToolParameters, ToolResult
from ..events.tool_events import BaseEvent, InfoEvent, ErrorEvent, TextEvent, StepEndEvent
from ..context import Context
from .base_agent import BaseAgent

class StructuredOutputAgent(BaseAgent):
    """结构化输出智能体，负责生成最终输出"""
    
    def __init__(
        self, 
        db_session: Optional[Session] = None, 
        engine_config: Any = None,
        step_id: int = 3
    ):
        super().__init__("structured_output", db_session, engine_config, step_id)
    
    async def process(self, context: Context) -> AsyncGenerator[BaseEvent, None]:
        """生成结构化输出"""
        # 获取整理后的内容
        organized_content = await context.get("organized_content", "")
        if not organized_content:
            yield ErrorEvent(message="未找到整理后的内容")
            return
        
        yield InfoEvent(message="生成结构化输出...")
        
        try:
            # 获取是否需要澄清
            needs_clarification = await context.get("needs_clarification", False)
            clarification_message = await context.get("clarification_message", "")
            
            # 如果需要澄清，输出澄清消息
            if needs_clarification and clarification_message:
                yield InfoEvent(message="问题需要澄清，输出澄清消息")
                yield TextEvent(message=f"我需要更多信息来回答您的问题：\n\n{clarification_message}")
                yield StepEndEvent(step=self.step_id)
                return
            
            # 检查是否需要生成后续问题
            further_questions = []
            if self.engine_config.further_questions and self.llm:
                yield InfoEvent(message="生成后续问题建议...")
                
                # 这里可以调用工具生成后续问题
                async for event in self.call_tool("further_questions_tool", {"content": organized_content}):
                    yield event
                    if hasattr(event, "result") and event.result and "questions" in event.result:
                        further_questions = event.result["questions"]
            
            # 输出最终回答
            yield TextEvent(message=organized_content)
            
            # 如果有后续问题，添加到输出
            if further_questions:
                further_questions_text = "\n\n您可能还想了解：\n" + "\n".join([f"- {q}" for q in further_questions])
                yield TextEvent(message=further_questions_text)
        
        except Exception as e:
            self.logger.error(f"生成结构化输出时出错: {str(e)}", exc_info=True)
            yield ErrorEvent(message=f"生成结构化输出时出错: {str(e)}")
            # 出错时直接输出整理后的内容
            yield TextEvent(message=organized_content)
        
        yield StepEndEvent(step=self.step_id)
```

## 3. 工作流引擎详细规范

### 3.1 上下文管理器 (backend/app/autoflow/context.py)

```python
from typing import Any, Dict, Optional
from datetime import datetime
import asyncio

class Context:
    """上下文管理器，用于在工作流中传递状态和数据"""
    
    def __init__(self, workflow=None):
        self._data = {}
        self._workflow = workflow
        self._lock = asyncio.Lock()
    
    async def set(self, key: str, value: Any) -> None:
        """设置上下文数据"""
        async with self._lock:
            self._data[key] = value
    
    async def get(self, key: str, default: Any = None) -> Any:
        """获取上下文数据"""
        async with self._lock:
            return self._data.get(key, default)
    
    async def update(self, data: Dict[str, Any]) -> None:
        """批量更新上下文数据"""
        async with self._lock:
            self._data.update(data)
    
    async def delete(self, key: str) -> None:
        """删除上下文数据"""
        async with self._lock:
            if key in self._data:
                del self._data[key]
    
    async def clear(self) -> None:
        """清空上下文数据"""
        async with self._lock:
            self._data.clear()
    
    async def keys(self) -> list:
        """获取所有键"""
        async with self._lock:
            return list(self._data.keys())
    
    async def has(self, key: str) -> bool:
        """检查键是否存在"""
        async with self._lock:
            return key in self._data
    
    def get_workflow(self):
        """获取关联的工作流"""
        return self._workflow
    
    def get_current_date(self) -> str:
        """获取当前日期字符串"""
        return datetime.now().strftime("%Y-%m-%d")
```

### 3.2 工作流引擎 (backend/app/autoflow/workflow.py)

```python
from typing import Any, Dict, List, Optional, AsyncGenerator, Type
import asyncio
import logging
from sqlmodel import Session

from .context import Context
from .events.tool_events import BaseEvent, InfoEvent, ErrorEvent, TextEvent, StepEndEvent
from .events.converter import EventConverter
from .agents.base_agent import BaseAgent
from .agents.question_optimizer_agent import QuestionOptimizerAgent
from .agents.qa_agent import QAAgent
from .agents.content_organizer_agent import ContentOrganizerAgent
from .agents.structured_output_agent import StructuredOutputAgent

from app.rag.chat.stream_protocol import ChatEvent

class Workflow:
    """工作流引擎，协调智能体执行"""
    
    def __init__(self, db_session: Optional[Session] = None, engine_config: Any = None):
        self.db_session = db_session
        self.engine_config = engine_config
        self.logger = logging.getLogger("autoflow.workflow")
        self.context = Context(self)
        self.event_converter = EventConverter()
        
        # 初始化智能体
        self.agents = [
            QuestionOptimizerAgent(db_session, engine_config, 0),
            QAAgent(db_session, engine_config, 1),
            ContentOrganizerAgent(db_session, engine_config, 2),
            StructuredOutputAgent(db_session, engine_config, 3)
        ]
    
    async def initialize(self, user_question: str, chat_history: List[Dict] = None) -> None:
        """初始化工作流"""
        if chat_history is None:
            chat_history = []
        
        # 设置初始上下文
        await self.context.set("user_question", user_question)
        await self.context.set("chat_history", chat_history)
        await self.context.set("start_time", asyncio.get_event_loop().time())
    
    async def run(self) -> AsyncGenerator[ChatEvent, None]:
        """执行工作流并生成事件流"""
        self.logger.info("开始执行工作流")
        
        try:
            # 依次执行每个智能体
            for agent in self.agents:
                self.logger.info(f"执行智能体: {agent.name}")
                
                # 处理智能体生成的事件
                async for event in agent.process(self.context):
                    # 转换为前端可用的ChatEvent
                    chat_event = self.event_converter.to_chat_event(event)
                    yield chat_event
            
            self.logger.info("工作流执行完成")
            
        except Exception as e:
            self.logger.error(f"工作流执行出错: {str(e)}", exc_info=True)
            # 生成错误事件
            error_event = ErrorEvent(message=f"工作流执行出错: {str(e)}")
            yield self.event_converter.to_chat_event(error_event)
```

### 3.3 AutoFlow代理 (backend/app/autoflow/autoflow_agent.py)

```python
from typing import Any, Dict, List, Optional, AsyncGenerator
import asyncio
import logging
from sqlmodel import Session

from app.rag.chat.stream_protocol import ChatEvent
from app.rag.types import ChatEventType

from .workflow import Workflow
from .tools.registry import ToolRegistry
from .context import Context

class AutoFlowAgent:
    """AutoFlow代理，作为系统对外接口"""
    
    def __init__(self, db_session: Optional[Session] = None, engine_config: Any = None):
        self.db_session = db_session
        self.engine_config = engine_config
        self.logger = logging.getLogger("autoflow.agent")
        
        # 初始化工具注册表
        self.tool_registry = ToolRegistry()
        
        # 初始化数据库聊天对象
        self.db_chat_obj = None
    
    def set_indices(self, knowledge_index=None, kg_index=None):
        """设置索引，用于向后兼容"""
        self.knowledge_index = knowledge_index
        self.kg_index = kg_index
    
    async def stream_chat(
        self, 
        query: str, 
        chat_history: List[Dict] = None, 
        db_chat_obj = None
    ) -> AsyncGenerator[ChatEvent, None]:
        """流式聊天接口"""
        if chat_history is None:
            chat_history = []
        
        self.db_chat_obj = db_chat_obj
        
        try:
            # 创建并初始化工作流
            workflow = Workflow(self.db_session, self.engine_config)
            await workflow.initialize(query, chat_history)
            
            # 如果有数据库聊天对象，添加到上下文
            if db_chat_obj:
                await workflow.context.set("db_chat_obj", db_chat_obj)
            
            # 执行工作流并生成事件流
            event_count = 0
            async for event in workflow.run():
                event_count += 1
                yield event
            
            self.logger.info(f"聊天完成，共生成 {event_count} 个事件")
            
        except Exception as e:
            self.logger.error(f"流式聊天出错: {str(e)}", exc_info=True)
            # 生成错误事件
            yield ChatEvent(
                event_type=ChatEventType.ERROR_PART,
                payload=f"聊天处理出错: {str(e)}"
            )
    
    async def _on_chat_complete(self, *args, **kwargs):
        """聊天完成回调，用于后处理"""
        pass
```

## 4. 工具实现详细规范

### 4.1 知识图谱工具 (backend/app/autoflow/tools/knowledge_graph_tool.py)

```python
from typing import Dict, List, Optional
from pydantic import BaseModel, Field
import logging

from ..tools.base import BaseTool, ToolParameters, ToolResult

class KnowledgeGraphParameters(ToolParameters):
    """知识图谱工具参数"""
    query: str
    depth: int = 2
    include_meta: bool = True
    with_degree: bool = True

class KnowledgeGraphResult(ToolResult):
    """知识图谱工具结果"""
    context: str = ""
    entities: List[Dict] = Field(default_factory=list)
    relationships: List[Dict] = Field(default_factory=list)

class KnowledgeGraphTool(BaseTool[KnowledgeGraphParameters, KnowledgeGraphResult]):
    """知识图谱工具，用于查询知识图谱"""
    
    def __init__(self, db_session=None, engine_config=None):
        super().__init__(
            name="knowledge_graph_tool",
            description="从知识图谱中检索实体和关系信息",
            parameter_type=KnowledgeGraphParameters,
            result_type=KnowledgeGraphResult
        )
        self.db_session = db_session
        self.engine_config = engine_config
        self.kg_index = None
    
    async def execute(self, parameters: KnowledgeGraphParameters) -> KnowledgeGraphResult:
        """执行知识图谱查询"""
        self.logger.info(f"执行知识图谱查询: {parameters.query[:50]}...")
        
        try:
            # 检查知识图谱是否启用
            if not self.engine_config or not hasattr(self.engine_config, "knowledge_graph") or not self.engine_config.knowledge_graph.enabled:
                self.logger.info("知识图谱未启用")
                return KnowledgeGraphResult(
                    success=True,
                    context="",
                    entities=[],
                    relationships=[]
                )
            
            # 获取知识库
            knowledge_bases = self.engine_config.get_knowledge_bases(self.db_session)
            if not knowledge_bases:
                self.logger.warning("未找到知识库")
                return KnowledgeGraphResult(success=False, error_message="未找到知识库")
            
            # 导入必要的模块
            from app.rag.retrievers.knowledge_graph.fusion_retriever import KnowledgeGraphFusionRetriever
            from app.rag.retrievers.knowledge_graph.schema import KnowledgeGraphRetrieverConfig
            
            # 创建知识图谱检索器
            kg_retriever = KnowledgeGraphFusionRetriever(
                db_session=self.db_session,
                knowledge_base_ids=[kb.id for kb in knowledge_bases],
                llm=self.engine_config.get_llama_llm(self.db_session),
                use_query_decompose=self.engine_config.knowledge_graph.using_intent_search,
                config=KnowledgeGraphRetrieverConfig(
                    depth=parameters.depth,
                    include_meta=parameters.include_meta,
                    with_degree=parameters.with_degree
                )
            )
            
            # 执行检索
            knowledge_graph = await self._run_async(
                kg_retriever.retrieve_knowledge_graph,
                parameters.query
            )
            
            # 生成知识图谱上下文
            context = ""
            if knowledge_graph:
                if self.engine_config.knowledge_graph.using_intent_search:
                    # 使用意图搜索模板
                    from llama_index.core.prompts.rich import RichPromptTemplate
                    if hasattr(self.engine_config.llm, "intent_graph_knowledge"):
                        kg_context_template = RichPromptTemplate(
                            self.engine_config.llm.intent_graph_knowledge
                        )
                        context = kg_context_template.format(
                            sub_queries=knowledge_graph.to_subqueries_dict(),
                        )
                else:
                    # 使用普通知识图谱模板
                    from llama_index.core.prompts.rich import RichPromptTemplate
                    if hasattr(self.engine_config.llm, "normal_graph_knowledge"):
                        kg_context_template = RichPromptTemplate(
                            self.engine_config.llm.normal_graph_knowledge
                        )
                        context = kg_context_template.format(
                            entities=knowledge_graph.entities,
                            relationships=knowledge_graph.relationships,
                        )
            
            # 返回结果
            return KnowledgeGraphResult(
                success=True,
                context=context,
                entities=[entity.model_dump() for entity in knowledge_graph.entities] if knowledge_graph else [],
                relationships=[rel.model_dump() for rel in knowledge_graph.relationships] if knowledge_graph else []
            )
            
        except Exception as e:
            self.logger.error(f"知识图谱查询出错: {str(e)}", exc_info=True)
            return KnowledgeGraphResult(
                success=False,
                error_message=f"知识图谱查询出错: {str(e)}"
            )
    
    async def _run_async(self, func, *args, **kwargs):
        """异步执行同步函数"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, lambda: func(*args, **kwargs))
```

### 4.2 知识库检索工具 (backend/app/autoflow/tools/knowledge_retrieval_tool.py)

```python
from typing import Dict, List, Optional, Any
from pydantic import BaseModel, Field
import logging
import asyncio

from ..tools.base import BaseTool, ToolParameters, ToolResult

class KnowledgeRetrievalParameters(ToolParameters):
    """知识库检索工具参数"""
    query: str
    top_k: int = 5

class KnowledgeRetrievalResult(ToolResult):
    """知识库检索工具结果"""
    nodes: List[Dict] = Field(default_factory=list)
    sources: List[Dict] = Field(default_factory=list)

class KnowledgeRetrievalTool(BaseTool[KnowledgeRetrievalParameters, KnowledgeRetrievalResult]):
    """知识库检索工具，用于从知识库中检索相关内容"""
    
    def __init__(self, db_session=None, engine_config=None):
        super().__init__(
            name="knowledge_retrieval_tool",
            description="从知识库中检索与查询相关的文档",
            parameter_type=KnowledgeRetrievalParameters,
            result_type=KnowledgeRetrievalResult
        )
        self.db_session = db_session
        self.engine_config = engine_config
        self.vector_index = None
    
    async def execute(self, parameters: KnowledgeRetrievalParameters) -> KnowledgeRetrievalResult:
        """执行知识库检索"""
        self.logger.info(f"执行知识库检索: {parameters.query[:50]}..., top_k={parameters.top_k}")
        
        try:
            # 检查是否有知识库
            if not self.db_session:
                self.logger.warning("数据库会话未初始化")
                return KnowledgeRetrievalResult(success=False, error_message="数据库会话未初始化")
            
            # 获取知识库
            knowledge_bases = self.engine_config.get_knowledge_bases(self.db_session)
            if not knowledge_bases:
                self.logger.warning("未找到知识库")
                return KnowledgeRetrievalResult(success=False, error_message="未找到知识库")
            
            # 导入必要的模块
            from llama_index.core.schema import QueryBundle
            from app.rag.retrievers.chunk.fusion_retriever import ChunkFusionRetriever
            
            # 创建向量检索器
            retriever = ChunkFusionRetriever(
                db_session=self.db_session,
                knowledge_base_ids=[kb.id for kb in knowledge_bases],
                llm=self.engine_config.get_llama_llm(self.db_session),
                config=self.engine_config.vector_search if hasattr(self.engine_config, "vector_search") else None,
                use_query_decompose=False,
            )
            
            # 执行检索
            nodes = await self._run_async(
                retriever.retrieve,
                QueryBundle(parameters.query)
            )
            
            # 处理检索结果
            result_nodes = []
            sources = []
            
            for node in nodes:
                try:
                    if hasattr(node, "node") and hasattr(node, "score"):
                        # NodeWithScore类型
                        node_dict = {
                            "text": node.node.text,
                            "score": node.score,
                            "metadata": node.node.metadata
                        }
                        result_nodes.append(node_dict)
                        
                        # 添加来源信息
                        source = {
                            "text": node.node.text[:100] + "...",
                            "metadata": node.node.metadata
                        }
                        sources.append(source)
                    elif hasattr(node, "text") and hasattr(node, "metadata"):
                        # 直接是Node对象
                        node_dict = {
                            "text": node.text,
                            "score": 1.0,  # 默认相似度
                            "metadata": node.metadata
                        }
                        result_nodes.append(node_dict)
                        
                        # 添加来源信息
                        source = {
                            "text": node.text[:100] + "...",
                            "metadata": node.metadata
                        }
                        sources.append(source)
                    elif isinstance(node, dict):
                        # 已经是字典格式
                        result_nodes.append(node)
                        
                        # 添加来源信息
                        source = {
                            "text": node.get("text", "")[:100] + "...",
                            "metadata": node.get("metadata", {})
                        }
                        sources.append(source)
                except Exception as node_e:
                    self.logger.error(f"处理节点失败: {str(node_e)}, 节点类型: {type(node).__name__}", exc_info=True)
                    continue
            
            # 返回结果
            return KnowledgeRetrievalResult(
                success=True,
                nodes=result_nodes,
                sources=sources
            )
            
        except Exception as e:
            self.logger.error(f"知识库检索出错: {str(e)}", exc_info=True)
            return KnowledgeRetrievalResult(
                success=False,
                error_message=f"知识库检索出错: {str(e)}"
            )
    
    async def _run_async(self, func, *args, **kwargs):
        """异步执行同步函数"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, lambda: func(*args, **kwargs))
```

### 4.3 数据库查询工具 (backend/app/autoflow/tools/database_query_tool.py)

```python
from typing import Dict, List, Optional, Any
from pydantic import BaseModel, Field
import logging
import asyncio

from ..tools.base import BaseTool, ToolParameters, ToolResult

class DatabaseQueryParameters(ToolParameters):
    """数据库查询工具参数"""
    query: str
    database_id: Optional[int] = None

class DatabaseQueryResult(ToolResult):
    """数据库查询工具结果"""
    results: str = ""
    sql: str = ""
    database_name: str = ""

class DatabaseQueryTool(BaseTool[DatabaseQueryParameters, DatabaseQueryResult]):
    """数据库查询工具，用于执行数据库查询"""
    
    def __init__(self, db_session=None, engine_config=None):
        super().__init__(
            name="database_query_tool",
            description="通过SQL查询数据库获取信息",
            parameter_type=DatabaseQueryParameters,
            result_type=DatabaseQueryResult
        )
        self.db_session = db_session
        self.engine_config = engine_config
    
    async def execute(self, parameters: DatabaseQueryParameters) -> DatabaseQueryResult:
        """执行数据库查询"""
        self.logger.info(f"执行数据库查询: {parameters.query[:50]}...")
        
        try:
            # 检查数据库查询是否启用
            if not self.engine_config or not hasattr(self.engine_config, "database") or not self.engine_config.database.enabled:
                self.logger.info("数据库查询未启用")
                return DatabaseQueryResult(
                    success=True,
                    results="",
                    sql="",
                    database_name=""
                )
            
            # 获取数据库连接
            database_connections = self.engine_config.get_linked_database_connections(self.db_session)
            if not database_connections:
                self.logger.warning("未找到数据库连接")
                return DatabaseQueryResult(success=False, error_message="未找到数据库连接")
            
            # 选择要查询的数据库
            target_connection = None
            if parameters.database_id:
                for conn in database_connections:
                    if conn.id == parameters.database_id:
                        target_connection = conn
                        break
            else:
                # 使用第一个数据库连接
                target_connection = database_connections[0]
            
            if not target_connection:
                self.logger.warning(f"未找到指定的数据库连接: {parameters.database_id}")
                return DatabaseQueryResult(success=False, error_message=f"未找到指定的数据库连接: {parameters.database_id}")
            
            # 导入必要的模块
            from app.rag.database.text_to_sql import TextToSQLProcessor
            
            # 创建文本到SQL处理器
            processor = TextToSQLProcessor(
                db_session=self.db_session,
                engine_config=self.engine_config,
                database_connection=target_connection
            )
            
            # 生成SQL
            sql_query = await self._run_async(
                processor.generate_sql,
                parameters.query
            )
            
            if not sql_query:
                self.logger.warning("未能生成SQL查询")
                return DatabaseQueryResult(
                    success=False,
                    error_message="未能生成SQL查询"
                )
            
            # 执行SQL查询
            query_results = await self._run_async(
                processor.execute_sql,
                sql_query
            )
            
            # 格式化查询结果
            formatted_results = await self._run_async(
                processor.format_results,
                query_results,
                parameters.query,
                sql_query
            )
            
            # 返回结果
            return DatabaseQueryResult(
                success=True,
                results=formatted_results,
                sql=sql_query,
                database_name=target_connection.name
            )
            
        except Exception as e:
            self.logger.error(f"数据库查询出错: {str(e)}", exc_info=True)
            return DatabaseQueryResult(
                success=False,
                error_message=f"数据库查询出错: {str(e)}"
            )
    
    async def _run_async(self, func, *args, **kwargs):
        """异步执行同步函数"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, lambda: func(*args, **kwargs))
```

### 4.4 后续问题生成工具 (backend/app/autoflow/tools/further_questions_tool.py)

```python
from typing import Dict, List, Optional
from pydantic import BaseModel, Field
import logging

from ..tools.base import BaseTool, ToolParameters, ToolResult

class FurtherQuestionsParameters(ToolParameters):
    """后续问题生成工具参数"""
    content: str

class FurtherQuestionsResult(ToolResult):
    """后续问题生成工具结果"""
    questions: List[str] = Field(default_factory=list)

class FurtherQuestionsTool(BaseTool[FurtherQuestionsParameters, FurtherQuestionsResult]):
    """后续问题生成工具，用于生成相关的后续问题"""
    
    def __init__(self, db_session=None, engine_config=None):
        super().__init__(
            name="further_questions_tool",
            description="根据内容生成相关的后续问题建议",
            parameter_type=FurtherQuestionsParameters,
            result_type=FurtherQuestionsResult
        )
        self.db_session = db_session
        self.engine_config = engine_config
        self.llm = None
        if engine_config and hasattr(engine_config, "get_llama_llm"):
            self.llm = engine_config.get_llama_llm(db_session)
    
    async def execute(self, parameters: FurtherQuestionsParameters) -> FurtherQuestionsResult:
        """执行后续问题生成"""
        self.logger.info("生成后续问题建议")
        
        try:
            # 检查是否启用后续问题生成
            if not self.engine_config or not self.engine_config.further_questions:
                self.logger.info("后续问题生成未启用")
                return FurtherQuestionsResult(
                    success=True,
                    questions=[]
                )
            
            # 检查LLM是否可用
            if not self.llm:
                self.logger.warning("LLM未配置，无法生成后续问题")
                return FurtherQuestionsResult(success=False, error_message="LLM未配置")
            
            # 获取提示词模板
            from llama_index.core.prompts.rich import RichPromptTemplate
            prompt_template = RichPromptTemplate(
                self.engine_config.llm.further_questions_prompt
            )
            
            # 生成后续问题
            recommend_questions = self.llm.predict(
                prompt_template,
                chat_message_content=parameters.content,
            )
            
            # 处理生成结果
            recommend_question_list = [
                q.strip() for q in recommend_questions.splitlines() if q.strip()
            ]
            
            # 校验生成质量
            if (
                any(c in recommend_questions for c in ("##", "**"))
                or max(len(q) for q in recommend_question_list) > 500
            ):
                # 重新生成格式错误的问题
                recommend_questions = self.llm.predict(
                    prompt_template,
                    chat_message_content=f"请生成问题列表。之前生成有误，请重试。\n{parameters.content}",
                )
                recommend_question_list = [
                    q.strip() for q in recommend_questions.splitlines() if q.strip()
                ]
            
            # 限制问题数量
            recommend_question_list = recommend_question_list[:5]
            
            # 返回结果
            return FurtherQuestionsResult(
                success=True,
                questions=recommend_question_list
            )
            
        except Exception as e:
            self.logger.error(f"生成后续问题出错: {str(e)}", exc_info=True)
            return FurtherQuestionsResult(
                success=False,
                error_message=f"生成后续问题出错: {str(e)}"
            )
```

## 5. 工具注册与初始化 (backend/app/autoflow/tools/init.py)

```python
from .registry import ToolRegistry
from .knowledge_graph_tool import KnowledgeGraphTool
from .knowledge_retrieval_tool import KnowledgeRetrievalTool
from .database_query_tool import DatabaseQueryTool
from .further_questions_tool import FurtherQuestionsTool

def register_default_tools(db_session=None, engine_config=None):
    """注册默认工具"""
    registry = ToolRegistry()
    
    # 注册知识图谱工具
    registry.register_tool(KnowledgeGraphTool(db_session, engine_config))
    
    # 注册知识库检索工具
    registry.register_tool(KnowledgeRetrievalTool(db_session, engine_config))
    
    # 注册数据库查询工具
    registry.register_tool(DatabaseQueryTool(db_session, engine_config))
    
    # 注册后续问题生成工具
    registry.register_tool(FurtherQuestionsTool(db_session, engine_config))
    
    return registry
```

## 6. 提示词更新 (backend/app/rag/default_prompt.py)

以下是工具调用模式所需的新增提示词模板，将添加到 `default_prompt.py` 文件中:

```python
# 工具使用决策提示词模板
TOOL_DECISION_PROMPT = """\
你是一个智能助手，需要决定如何回答用户问题。请分析用户问题，判断应该使用哪些工具来获取最佳回答。

可用工具:
1. knowledge_graph_tool - 从知识图谱中检索实体和关系信息
   - 适用于：需要了解概念之间关系、实体属性、领域术语定义等问题
   - 参数：query(查询文本), depth(搜索深度), include_meta(是否包含元数据), with_degree(是否包含关联度)

2. knowledge_retrieval_tool - 从知识库中检索与查询相关的文档
   - 适用于：需要详细解释、背景信息、教程、指南等内容的问题
   - 参数：query(查询文本), top_k(返回结果数量)

3. database_query_tool - 通过SQL查询数据库获取信息
   - 适用于：需要精确数值、统计信息、结构化数据的问题
   - 参数：query(查询文本), database_id(可选，指定数据库ID)

用户问题: {{query_str}}

请分析问题并决定使用哪些工具:
1. 首先确定问题类型（概念解释、数据查询、流程指导等）
2. 考虑哪些工具最适合回答此类问题
3. 如果需要多种信息源，可以组合使用工具

回答格式:
```json
{
  "reasoning": "解释你为什么选择这些工具",
  "tools": [
    {
      "name": "工具名称",
      "parameters": {
        "参数名": "参数值"
      }
    }
  ]
}
```

仅返回JSON格式结果，不要添加其他解释或前缀。
"""

# 推理分析提示词模板
REASONING_ANALYSIS_PROMPT = """\
Current Date: {{current_date}}
---------------------
Knowledge graph information is below
---------------------

{{graph_knowledges}}

---------------------
Context information is below.
---------------------

{{context_str}}

---------------------

任务: 整理并分析下方提供的内容，使其更有条理、更易理解。

请遵循以下指导:

1. 内容整理与结构化:
   - 识别主题和关键点
   - 按照逻辑顺序重组信息
   - 创建清晰的章节和小标题
   - 将类似信息归类在一起
   - 使用Markdown格式（标题、列表、表格等）提高可读性

2. 内容增强:
   - 解释复杂的技术术语和概念
   - 添加必要的上下文信息
   - 确保解释准确完整
   - 保持专业的技术深度

3. 改进形式但保留实质:
   - 保留所有重要信息和技术细节
   - 不添加原文未包含的新事实
   - 确保技术准确性
   - 保留原文的专业性和技术深度

4. 语言清晰化:
   - 使用准确、专业的技术语言
   - 改善句子结构
   - 修正任何语法或拼写错误
   - 保持与原始内容相同的语言

5. 格式规范:
   - 针对代码示例，保持原有的代码块格式
   - 如有表格数据，转换为Markdown表格
   - 保留原有的引用和脚注格式

原始问题:
{{query_str}}

请对以上内容进行整理与分析:
"""

# 混合响应合成提示词模板
HYBRID_RESPONSE_SYNTHESIS_PROMPT = """\
Current Date: {{current_date}}
---------------------
知识库内容:
---------------------

{{context_str}}

---------------------
数据库查询结果:
---------------------

{{database_results}}

---------------------

引用格式:

使用markdown脚注语法（例如：[^1]）来标注信息来源。
每个脚注必须对应一个唯一的来源。请勿为多个脚注使用相同的来源。

### 正确脚注用法示例（注意来源的唯一性和多样性）：
<!-- 格式: knowledge://chunk/id/{块ID} -->
[^1]: [TiDB 概览](knowledge://chunk/id/9cdb3cce42ae4c6ab6ce2221a2241414)
[^2]: [TiDB 架构](knowledge://chunk/id/9cdb3cce42ae4c6ab6ce2221a2241415)

使用数据库查询结果作为来源时，使用以下脚注格式：
[^n]: [Database: DatabaseName](database://query/id/{database_connection_id})

---------------------

你是一位专业的技术顾问，需要回答以下问题：

{{query_str}}

请遵循以下指导：
1. 综合分析知识库内容和数据库查询结果
2. 如果数据库结果与知识库内容有冲突，优先使用数据库结果，因为它们可能更新
3. 对数据库查询结果进行解释，说明其与问题的相关性
4. 使用脚注标明信息来源
5. 如果无法从提供的信息中找到答案，清晰地说明这一点
6. 保持回答的技术准确性和专业性
7. 使用与问题相同的语言回答

回答：
"""
```

## 7. 提示词配置注册 (backend/app/rag/chat/config.py)

将以上提示词模板添加到 `LLMOption` 类中:

```python
class LLMOption(BaseModel):
    """
    语言模型(LLM)选项配置类
    
    这个类定义了与语言模型相关的各种提示词模板，用于指导AI如何回答不同类型的问题。
    提示词是指引导AI生成特定类型回答的文本指令。
    """
    # 现有提示词定义...
    
    # 用于工具使用决策的提示词模板
    tool_decision_prompt: str = DEFAULT_TOOL_DECISION_PROMPT
    
    # 用于推理分析的提示词模板
    reasoning_analysis_prompt: str = DEFAULT_REASONING_ANALYSIS_PROMPT
    
    # 混合内容（知识库+数据库结果）的回答生成提示词模板
    hybrid_response_synthesis_prompt: str = DEFAULT_HYBRID_RESPONSE_SYNTHESIS_PROMPT
```

## 8. 工具初始化和注册 (backend/app/autoflow/tools/init.py)

现在我们需要确保所有工具在应用启动时被正确注册:

```python
# 在 backend/app/__init__.py 中添加

def init_autoflow(db_session=None, engine_config=None):
    """初始化AutoFlow系统"""
    from app.autoflow.tools.init import register_default_tools
    
    # 注册默认工具
    registry = register_default_tools(db_session, engine_config)
    
    # 日志记录已注册的工具
    from logging import getLogger
    logger = getLogger("app")
    logger.info(f"AutoFlow工具已注册: {', '.join(registry.list_tools())}")
    
    return registry
```

## 9. 工作流集成 (backend/app/rag/chat/chat_service.py)

修改聊天服务使用新的工作流系统:

```python
# 在 chat 函数中修改以下部分

# 判断是否使用AutoFlow工作流
if engine_config.agent.enabled:
    try:
        # 导入并初始化AutoFlow代理
        from app.autoflow.autoflow_agent import AutoFlowAgent
        
        logger.info(f"【聊天服务】使用AutoFlow工作流处理请求")
        
        autoflow_agent = AutoFlowAgent(db_session, engine_config)
        
        # 设置索引以兼容旧版本接口
        from app.autoflow.tools.init import register_default_tools
        register_default_tools(db_session, engine_config)
        
        # 转换聊天历史格式
        chat_history_list = []
        for i, message in enumerate(chat_messages[:-1]):
            chat_history_list.append({
                "role": "user" if message.role == "user" else "assistant",
                "content": message.content
            })
        
        # 初始化状态
        yielded_first = False
        current_message = ""
        
        # 流式生成回答
        async for event in autoflow_agent.stream_chat(
            chat_messages[-1].content, 
            chat_history_list, 
            db_chat_obj
        ):
            # 转换事件为前端可用的格式
            if not yielded_first:
                # 首个事件包含聊天开始标记
                yield ChatEvent(
                    event_type=ChatEventType.CHAT_START,
                    payload={"chatId": str(chat_id), "engineName": engine_name}
                )
                yielded_first = True
            
            # 输出事件
            yield event
    
    except Exception as e:
        # 异常处理
        logger.error(f"【聊天服务】AutoFlow处理出错: {str(e)}", exc_info=True)
        yield ChatEvent(
            event_type=ChatEventType.ERROR_PART,
            payload=f"处理请求时出错: {str(e)}"
        )
else:
    # 使用传统处理方式
    # 原有代码...
```

## 10. 单元测试规范

为了确保工作流系统的稳定性和可靠性，需要编写以下单元测试:

### 10.1 工具框架测试 (tests/autoflow/tools/test_tools.py)

```python
import pytest
import asyncio
from app.autoflow.tools.base import BaseTool, ToolParameters, ToolResult
from app.autoflow.tools.registry import ToolRegistry
from pydantic import BaseModel

class SimpleParameters(ToolParameters):
    query: str

class SimpleResult(ToolResult):
    answer: str

class SimpleTool(BaseTool[SimpleParameters, SimpleResult]):
    def __init__(self):
        super().__init__(
            name="simple_tool",
            description="A simple test tool",
            parameter_type=SimpleParameters,
            result_type=SimpleResult
        )
    
    async def execute(self, parameters: SimpleParameters) -> SimpleResult:
        return SimpleResult(answer=f"Answer for: {parameters.query}")

@pytest.fixture
def registry():
    registry = ToolRegistry()
    # 确保创建新的注册表实例
    registry._tools = {}
    return registry

@pytest.mark.asyncio
async def test_tool_registration(registry):
    # 创建工具
    tool = SimpleTool()
    
    # 注册工具
    registry.register_tool(tool)
    
    # 验证工具已注册
    assert "simple_tool" in registry.list_tools()
    
    # 获取工具
    retrieved_tool = registry.get_tool("simple_tool")
    assert retrieved_tool is not None
    assert retrieved_tool.name == "simple_tool"
    
    # 测试元数据
    metadata = retrieved_tool.get_metadata()
    assert metadata["name"] == "simple_tool"
    assert metadata["description"] == "A simple test tool"
    assert "parameters" in metadata
    assert "result" in metadata

@pytest.mark.asyncio
async def test_tool_execution():
    # 创建工具
    tool = SimpleTool()
    
    # 执行工具
    result = await tool.execute(SimpleParameters(query="test query"))
    
    # 验证结果
    assert isinstance(result, SimpleResult)
    assert result.success is True
    assert result.answer == "Answer for: test query"
```

### 10.2 工作流集成测试 (tests/autoflow/test_workflow.py)

```python
import pytest
import asyncio
from unittest.mock import MagicMock, patch
from app.autoflow.workflow import Workflow
from app.autoflow.context import Context
from app.autoflow.events.tool_events import InfoEvent, TextEvent, StepEndEvent

@pytest.fixture
def mock_session():
    return MagicMock()

@pytest.fixture
def mock_config():
    config = MagicMock()
    config.refine_question_with_kg = False
    config.further_questions = False
    return config

@pytest.mark.asyncio
async def test_workflow_initialization(mock_session, mock_config):
    # 创建工作流
    workflow = Workflow(mock_session, mock_config)
    
    # 初始化工作流
    await workflow.initialize("Test question", [])
    
    # 验证上下文
    assert await workflow.context.get("user_question") == "Test question"
    assert await workflow.context.get("chat_history") == []
    assert await workflow.context.get("start_time") is not None

@pytest.mark.asyncio
async def test_workflow_simple_execution(mock_session, mock_config):
    # 创建工作流
    workflow = Workflow(mock_session, mock_config)
    
    # 初始化工作流
    await workflow.initialize("Test question", [])
    
    # 收集生成的事件
    events = []
    async for event in workflow.run():
        events.append(event)
    
    # 验证事件流
    assert len(events) > 0
    
    # 验证至少有一个TEXT_PART事件（最终回答）
    text_events = [e for e in events if e.event_type == "2"]
    assert len(text_events) > 0
```

## 11. 实施计划与里程碑

以下是实施这个工具调用模式工作流改造的分阶段计划:

### 阶段一: 基础框架与工具实现 (周1-2)

1. **基础工具框架**
   - 实现 BaseTool 和 ToolRegistry
   - 实现基本事件类型和转换器
   - 编写单元测试验证工具调用

2. **核心工具实现**
   - 知识图谱工具
   - 知识库检索工具
   - 数据库查询工具
   - 后续问题生成工具

3. **里程碑验收标准**: 能够独立调用各工具并获取正确结果

### 阶段二: 智能体与工作流实现 (周2-3)

1. **智能体系统实现**
   - 基础智能体框架
   - 优化问题智能体
   - 问答智能体
   - 内容整理智能体
   - 结构化输出智能体

2. **工作流引擎实现**
   - 上下文管理器
   - 工作流协调器
   - AutoFlow代理

3. **里程碑验收标准**: 能够执行简单工作流，各智能体之间正确传递上下文

### 阶段三: 提示词更新与集成 (周4)

1. **提示词更新**
   - 更新 default_prompt.py 添加新提示词
   - 更新配置系统支持新提示词
   - 测试提示词效果

2. **系统集成**
   - 将 AutoFlow 集成到聊天服务
   - 添加兼容层处理事件转换
   - 实现与前端的事件通信

3. **里程碑验收标准**: 完整的工作流能在现有系统中运行，生成符合前端期望的事件

### 阶段四: 测试与优化 (周5)

1. **全面测试**
   - 单元测试覆盖所有关键组件
   - 集成测试验证工作流
   - 端到端测试验证与前端交互

2. **性能优化**
   - 分析性能瓶颈
   - 优化关键路径
   - 添加缓存策略

3. **里程碑验收标准**: 系统稳定运行，无重大错误，性能达到预期

## 12. 注意事项与风险管理

1. **系统兼容性**
   - 工具调用模式与现有系统的集成可能存在兼容性问题
   - 缓解策略: 添加适配层，使用事件转换器确保生成的事件符合前端期望

2. **性能考量**
   - 多步骤工作流可能导致响应延迟
   - 缓解策略: 实现异步处理，添加流式响应，优化关键路径

3. **错误处理**
   - 工作流中的任何节点失败可能导致整个流程失败
   - 缓解策略: 全面的错误捕获和恢复机制，确保即使某步骤失败仍能生成有用的回应

4. **扩展性**
   - 系统需要支持未来添加新工具和新智能体
   - 缓解策略: 使用注册机制和通用接口，确保系统能轻松扩展

5. **测试覆盖**
   - 工作流系统复杂，难以测试所有可能的路径
   - 缓解策略: 构建自动化测试套件，专注于关键路径，实现高测试覆盖率
